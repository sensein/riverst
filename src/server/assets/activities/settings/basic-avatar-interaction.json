{
  "title": "Basic Avatar Interaction Configuration",
  "description": "Schema for configuring a basic avatar interaction activity.",
  "type": "object",
  "properties": {
    "name": {
      "type": "string",
      "const": "basic-avatar-interaction"
    },
    "description": {
      "type": "string",
      "const": "Basic avatar interaction activity."
    },
    "options": {
      "type": "object",
      "properties": {
        "advanced_flows": {
          "type": "boolean",
          "const": false,
          "default": false,
          "description": "This activity only supports basic flows. Advanced flows are not allowed for the basic avatar interaction activity and must be set to false."
        },
        "pipeline_modality": {
          "type": "string",
          "enum": ["classic", "e2e"],
          "default": "classic",
          "description": "The modality of the pipeline. This is set to 'classic' for the stt, llm and tts pipeline, and to 'e2e' for the end to end pipeline + tts. The e2e modality is not very stable and should be used with caution."
        },
        "llm_type": {
          "type": "string",
          "enum": ["openai", "openai_realtime_beta", "gemini", "llama3.2"],
          "default": "openai",
          "description": "The LLM service to use."
        },
        "stt_type": {
          "type": "string",
          "enum": ["whisper", "openai"],
          "default": "openai",
          "description": "The STT service to use."
        },
        "tts_type": {
          "type": "string",
          "enum": ["kokoro", "elevenlabs"],
          "default": "kokoro",
          "description": "The TTS service to use."
        },
        "body_animations": {
          "type": "array",
          "items": {
            "type": "string",
            "enum": ["dance", "wave", "i_have_a_question", "thank_you", "i_dont_know", "ok", "thumbup", "thumbdown", "happy", "sad", "angry", "fear", "disgust", "love", "sleep"]
          },
          "default": ["dance", "wave", "i_have_a_question", "thank_you", "i_dont_know", "ok", "thumbup", "thumbdown", "happy", "sad", "angry", "fear", "disgust", "love", "sleep"],
          "description": "List of body animations that the avatar can perform."
        },
        "camera_settings": {
          "type": "string",
          "enum": ["full", "mid", "upper", "head"],
          "default": "upper",
          "description": "Select the camera framing used for the avatar during the interaction."
        },
        "avatar_system_prompt": {
          "type": "string",
          "maxLength": 500,
          "default": "You are an interactive robot. Keep your responses brief (one or two sentences at most). Your output will be converted to audio so don't include special characters in your answers. Respond to what the user said in a creative and helpful way. Start the conversation by introducing yourself and trigger the 'wave' animation.",
          "description": "Instructions defining how the avatar should behave during the interaction."
        },
        "avatar_personality_description": {
          "type": "string",
          "maxLength": 500,
          "default": "You are the Riverst avatar, a friendly, helpful robot.",
          "description": "Text describing the avatar’s personality and role."
        },
        "task_description": {
          "type": "string",
          "maxLength": 500,
          "default": "Demonstrate how you can interact with the user in a short conversation. Assist the user with their requests.",
          "description": "Free-text description of the task or goal of the interaction."
        },
        "user_description": {
          "type": "string",
          "maxLength": 500,
          "description": "Optional free-text field to describe the user."
        },
        "long_term_memory": {
          "type": "boolean",
          "default": false,
          "description": "Enable or disable long-term memory. If enabled, the avatar will remember information from previous interactions and use it to guide the conversation."
        },
        "languages": {
          "type": "array",
          "items": {
            "type": "string",
            "enum": ["english", "italian", "spanish", "german"]
          },
          "default": ["english"],
          "description": "List of languages supported by the avatar. If empty, the avatar supports all languages in the intersection of the languages supported by the STT, LLM and TTS services."
        },
        "video_flag": {
          "type": "boolean",
          "default": false,
          "description": "Enable or disable video processing during the session."
        },
        "video_out_width": {
          "type": "integer",
          "const": 640,
          "default": 640,
          "description": "Width of the video output in pixels."
        },
        "video_out_height": {
          "type": "integer",
          "const": 320,
          "default": 320,
          "description": "Height of the video output in pixels."
        },
        "video_out_framerate": {
          "type": "integer",
          "const": 30,
          "default": 30,
          "description": "Framerate of the video output in frames per second."
        },
        "user_transcript": {
          "type": "boolean",
          "default": false,
          "description": "Enable showing the transcript of the user’s speech."
        },
        "bot_transcript": {
          "type": "boolean",
          "default": false,
          "description": "Enable showing the transcript of the avatar’s speech."
        }
      },
      "required": [
        "advanced_flows",
        "camera_settings",
        "task_description",
        "avatar_personality_description",
        "avatar_system_prompt",
        "video_flag",
        "user_transcript",
        "bot_transcript"
      ]
    }
  },
  "required": ["name", "description", "options"]
}
